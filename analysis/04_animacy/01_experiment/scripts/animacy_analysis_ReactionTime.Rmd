---
title: "Animacy Nouns: Analysis"
author: "morgan moyer"
date: "`r Sys.Date()`"
output: pdf_document
---


```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../helpers.R")

d <- read.csv("../data/processed.csv")
```



```{r}

ggplot(d, aes(x=LogReactionTime)) +
  geom_histogram(binwidth = .1,fill = "lightblue", color = "black") +
  facet_wrap(~Task)

ggplot(d, aes(x=LogReactionTime, fill=Task)) +
  geom_density(alpha = .4)

```

# Interaction between accuracy and task?
```{r}
names(d)
dcen <- d %>% 
  mutate(Word = as.factor(Word),
         ID.true = as.factor(ID.true),
         Task = as.factor(Task),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cTask = as.numeric(Task)-mean(as.numeric(Task)))

m <- lmer(LogReactionTime ~ cAccuracy*cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m)
```


```{r}
agr <- d %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5)
  # guides(legend = "none")
  # theme(legend.position = "none")  # Remove the legend
# ggsave("../graphs/nouns2_accXrt.pdf",width = 5, height = 3)

```

# Look at words most accurate for animacy

```{r}
# Compute highest accuracy for Concrete
concrete_accuracy <- d %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime)) %>% 
  filter(Task == "Animacy") %>%
  select(Word, MeanAccuracy) %>%
  rename(AnimacyAccuracy = MeanAccuracy) %>% 
  arrange(desc(AnimacyAccuracy)) %>% 
  head(10)


agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))

ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5)
  # guides(legend = "none")
  # theme(legend.position = "none")  # Remove the legend
# ggsave("../graphs/exp1b_accXrt.pdf",width = 5, height = 3)

```

```{r}
agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>% 
  reframe(MeanAccuracy = mean(Accuracy), 
          CILow = ci.low(Accuracy), 
          CIHigh = ci.high(Accuracy)) %>%
  mutate(YMin = MeanAccuracy - CILow, 
         YMax = MeanAccuracy + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanAccuracy, fill = Task)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9))
```

```{r}
agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>% 
  reframe(MeanReactionTime = mean(ReactionTime), 
          CILow = ci.low(ReactionTime), 
          CIHigh = ci.high(ReactionTime)) %>%
  mutate(YMin = MeanReactionTime - CILow, 
         YMax = MeanReactionTime + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanReactionTime, fill = Task)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9))
```


# First Remove participants who aren't super, aggregating over Task

```{r}
length(unique(d$ID.true))
inacc.parts <- d %>% 
  group_by(ID.true,Task) %>% 
  summarise(MeanAccuracy = mean(Accuracy)) %>% 
  filter(MeanAccuracy < .75)

# How many participants have Accuracy < .75?
length(unique(inacc.parts$ID.true))

d.inaccurate.removed <- d %>% 
  anti_join(inacc.parts, by = "ID.true")

# Sanity check
length(unique(d.inaccurate.removed$ID.true))


# remove all inaccurate trials
orig <- nrow(d.inaccurate.removed)
d.inaccurate.removed <- d.inaccurate.removed %>% 
  filter(Accuracy == 1)
nrow(d.inaccurate.removed)/orig*100

# Remove subjects with ReactionTime higher than 3x IQR
summary(d.inaccurate.removed$LogReactionTime)
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 6.924   7.328   7.436   7.479   7.579  10.008 
range(d.inaccurate.removed$LogReactionTime)

hist(d.inaccurate.removed$LogReactionTime, breaks=100, col="lightblue", xlab="LogReactionTime (ms)",
        main="Histogram with Normal Curve")

quantile(d.inaccurate.removed$LogReactionTime)
IQR(d.inaccurate.removed$LogReactionTime)*3 # 0.7526289
cutoff.high <- quantile(d.inaccurate.removed$LogReactionTime)[4] + IQR(d.inaccurate.removed$LogReactionTime)*3 # 8.419261
cutoff.low <- quantile(d.inaccurate.removed$LogReactionTime)[2] - IQR(d.inaccurate.removed$LogReactionTime)*3# 6.5088838.419261


# remove subjects with ReactionTime higher than 3 x IQR
df.outliers.removed <- subset(d.inaccurate.removed, (d.inaccurate.removed$LogReactionTime > cutoff.low) & (d.inaccurate.removed$LogReactionTime < cutoff.high))

hist(df.outliers.removed$LogReactionTime, col="lightblue", xlab="LogReactionTime (ms)",
        main="Histogram with Normal Curve")


```


```{r}
ggplot(df.outliers.removed, aes(x=LogReactionTime, fill=Task)) +
  # facet_wrap(~BlockOrder) +
  geom_density(alpha = .4)

ggplot(df.outliers.removed, aes(x=ReactionTime, fill=Task)) +
  # facet_wrap(~BlockOrder) +
  geom_density(alpha = .4)


```


# convert everything to factors
```{r, include=FALSE, warning=FALSE, echo=FALSE}
str(d)

convert_except <- function(df, exclude_cols) {
  df[] <- lapply(names(df), function(col_name) {
    if (!(col_name %in% exclude_cols)) {
      return(as.factor(df[[col_name]]))  # Convert to factor if not in excluded columns
    } else {
      return(df[[col_name]])  # Leave the excluded columns unchanged
    }
  })
  return(df)
}
# Specify columns to exclude from conversion
exclude_columns <- c('ReactionTime', 'LogReactionTime')

# Convert all columns to factors except for 'a' and 'd'
df_factors <- convert_except(df.outliers.removed, exclude_columns)


```


```{r, include=FALSE, warning=FALSE, echo=FALSE}
contrasts(df_factors$Task)

center = df_factors %>%
  mutate(cTask = as.numeric(Task)-mean(as.numeric(Task)),
         cAnimacy = as.numeric(Animacy)-mean(as.numeric(Animacy)),
         cValence = as.numeric(Valence)-mean(as.numeric(Valence)),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cBlockOrder = as.numeric(BlockOrder)-mean(as.numeric(BlockOrder))
         )
  
  # droplevels()
```

# Is there an effect of Task?
No

```{r}

m = lmer(LogReactionTime ~ cTask + (1+cTask|ID.true) + (1+cTask|Word), data=center)
summary(m)
```


# Does Accuracy predict reaction time? 

In other words, is reaction time affected by certainty about the categorization?
- No.
```{r}

m = lmer(LogReactionTime ~ cTask*cAccuracy + (1+cTask|ID.true) + (1+cTask|Word), data=center)
summary(m)

```


# Main Effect of Block Order 

## On ReactionTime
- No.
```{r}
m = lmer(LogReactionTime ~ cBlockOrder + (1|ID.true) + (1+cBlockOrder|Word), data=center)

summary(m)
```



# effect of word features on ReactionTime?
yes
```{r}

m = lmer(LogReactionTime ~ cValence*cAnimacy + (1+cValence+cAnimacy|ID.true) + (1+cValence+cAnimacy|Word), data=center)

summary(m)

```


```{r}

m = lmer(LogReactionTime ~ cTask*cValence*cAnimacy + (1+cTask+cValence+cAnimacy|ID.true) + (1+cTask+cValence+cAnimacy|Word), data=center)

summary(m)

```


