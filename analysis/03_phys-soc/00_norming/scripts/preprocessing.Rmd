---
title: 'Adjs soc-phys Norming: preprocessing'
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../../helpers.R")
```


```{r}
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}

# Read in the results
d <- read.pcibex("../data/results.csv")

facts <- read.csv("../data/adjs_list.csv")

names(d)
length(unique(d$ID.Ibex))
# length(unique(facts$Word))

nrow(d)

```

```{r}
nrow(d)
# Remove old participant
d <- d %>% 
  filter(!ID.Ibex %in% c("5bc9f8b677740000016a08b5"))

nrow(d)
length(unique(d$ID.Ibex))

d <- d %>% 
  filter((Label == "rating_task"),
         (PennElementType %in% c("Var","Scale"))) 

nrow(d)
length(unique(d$ID.Ibex))

# View(d)

d <- d[,c("ID.Ibex","Label","PennElementType","PennElementName","Value","Order.number.of.item")]

# Wide to long 
# Step 2: Pivot wider to reshape
df_wide <- d %>%
  pivot_wider(
    id_cols = c(ID.Ibex, Order.number.of.item),
    names_from = PennElementName,
    values_from = Value
  )

# Convert likert to numeric
df_final <- df_wide %>%
  mutate(likert = as.numeric(likert))

# View(d)
nrow(df_final)
# Sanity check
length(unique(df_final$Word))
length(unique(df_final$ID.Ibex))
table(df_final$Group)

# Combine data with factors
df_final <- df_final %>% 
  left_join(facts, by = "Word") %>% 
  # rename
  rename(Likert = likert)
names(df_final)


# Write to .csv aggregating over participants
agr <- df_final %>% 
  group_by(Word) %>% 
  summarize(SocPhys.Mean = mean(Likert),
            SocPhys.SD = sd(Likert)) %>% 
  left_join(facts, by = "Word")

write.csv(agr,"../data/norming_agg.csv")

# Write to .csv not aggregating over participants
write.csv(df_final,"../data/processed.csv")

```


# Take a look at comments and Problems
```{r}
unique(d$PennElementType)
comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Comments"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Problems"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "NativeLang"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "OtherLangs"))

unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Gender"))
unique(comments$Value)
```



# training items to csv

```{r}


write.csv(d.train,"../data/processed_training.csv")

table(d.train$Task)

```
