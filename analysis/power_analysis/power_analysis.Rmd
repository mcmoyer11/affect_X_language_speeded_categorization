---
  title: "Power Analysis"
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---
  
```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(simr)
library(pwr)
library(MASS)  # For generating random data
library(lme4)

cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
# source("../../helpers.R")
d <- read.csv("../00_pilot/01_verbs/05_pilot/data/processed.csv")
```

# First, specify the experimental structure

Task (2) x ConcValCombo (4)

```{r}
# Power analysis for ANOVA with 9 groups (3x3), medium effect size

# result <- pwr.anova.test(k = 2, f = 0.25, sig.level = 0.05, power = 0.8)

result <- pwr.t.test(d = 0.5, sig.level = 0.05, power = 0.8, type = "two.sample")

print(result)
```


# Usling LMER

Fit your model using lmer

Use the simr package to simulate data based on your model

Estimate power by running multiple simulations

This approach allows you to calculate power for complex mixed-effects models, taking into account both fixed and random effects36. It's particularly useful for designs with multiple random factors, such as participants and items, which are common in many experimental settings.

The simr package also provides tools for creating power curves, which can help you determine the required sample size for a desired level of power5. This can be especially helpful when planning studies or writing grant proposals.

It's worth noting that while this simulation-based approach is flexible and powerful, it can be computationally intensive, especially for complex models or large datasets18.


```{r}

# Fit your model
fit <- lmer(LogReactionTime ~ Task + 
            (1+Task|Word) + 
            (1+Task|ID.true) + 
              # random slope for the repeated measure factor 
              # and interaction term to represent the repetition
            (1+Task|ID.true:Word), 
            data = d)

summary(fit)
# Run power analysis
# 1. Modify the model to specify the desired sample size
extended_fit <- extend(fit, along = "ID.true", n = 40)  # Replace "ID.true" with your grouping variable

# 2. Run the power analysis on the extended model
power <- powerSim(extended_fit, nsim = 200)
print(power)

```


Power for predictor 'Task', (95% confidence interval):
      100.0% (98.17, 100.0)

Test: unknown test

Based on 200 simulations, (107 warnings, 0 errors)
alpha = 0.05, nrow = 9600

Time elapsed: 0 h 28 m 18 s

nb: result might be an observed power calculation


```{r}


# Extract fixed-effect estimates from the model
# Extract fixed-effect estimates from the model
beta <- fixef(fit)  # Fixed effects

# Extract standard deviation of residuals (sigma) and random effects
sigma_resid <- sigma(fit)  # Residual standard deviation
var_components <- VarCorr(fit)  # Random effect variances

# Generate new response values based on model estimates
new_d$LogReactionTime <- rnorm(nrow(new_d), mean = beta[1], sd = sigma_resid)


# Refit model on simulated data
new_fit <- lmer(LogReactionTime ~ Task + 
                (1+Task|Word) + 
                (1+Task|ID.true) + 
                (1+Task|ID.true:Word), 
                data = new_d)

summary(new_fit)
# 2. Run the power analysis on the extended model
power <- powerSim(new_fit, nsim = 200)
print(power)
```

# This one seems to work

```{r}
# Simplify random effects:
fit_simple <- lmer(LogReactionTime ~ Task + 
                   (1 | Word) +          # Remove Task slope for Word
                   (1 + Task || ID.true) +   # Uncorrelated slopes/intercepts
                   (1 | ID.true:Word),   # Remove Task slope for interaction
                 data = d)


extended_fit <- extend(fit_simple, along = "ID.true", n = 20)  # Replace "ID.true" with your grouping variable

# 2. Run the power analysis on the extended model
power <- powerSim(extended_fit, nsim = 200)
print(power)
```

## Second try n=40

Power for predictor 'Task', (95% confidence interval):
      100.0% (98.17, 100.0)

Test: unknown test

Based on 200 simulations, (199 warnings, 0 errors)
alpha = 0.05, nrow = 9600

Time elapsed: 0 h 11 m 11 s

nb: result might be an observed power calculation




## First try, n=80 is overpowered
n=80 

Power for predictor 'Task', (95% confidence interval):
      100.0% (98.17, 100.0)

Test: unknown test

Based on 200 simulations, (200 warnings, 0 errors)
alpha = 0.05, nrow = 19200

Time elapsed: 0 h 21 m 17 s

nb: result might be an observed power calculation


TTL;DR
Overpowered


## Run a power curve
```{r}
fit <- lmer(LogReactionTime ~ Task + 
            (1+Task|Word) + 
            (1+Task|ID.true), 
            # (1+Task|ID.true:Word), 
            data = d)

# Run the power curve
power_curve <- powerCurve(fit_simple, along = "ID.true", breaks = seq(20, 80, by = 10), nsim = 200)

# Plot the power curve
plot(power_curve)

summary(power_curve)
isSingular(fit_simple, tol = 1e-4)

```


```{r}
library(brms)
brm_model <- brm(LogReactionTime ~ Task + (1 + Task | Word) + (1 + Task | ID.true), 
                 data = d, prior = set_prior("normal(0,1)", class = "sd"))

```

