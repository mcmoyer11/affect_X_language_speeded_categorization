---
title: "Concret/Abstract Dimension for Verbs,Nouns,Adjs"
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
library(kableExtra)
theme_set(theme_bw())
library(ggrepel)
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../../../helpers.R")

# v1 <- read_csv("../../01_verbs/exploratory_all_data/data/processed.csv")
# v1["Category"] <- "Verbs"

v <- read_csv("../../01_verbs/data/processed.csv")
v["Category"] <- "Verbs"

n2 <- read_csv("../../02_nouns/data/processed.csv")
n2["Category"] <- "Nouns"


a1 <- read_csv("../../03_adjectives/data/processed.csv")
a1["Category"] <- "Adjs"


d <- bind_rows(v,n2,a1)

# table(d$WhoseList)
```


# Summary Stats
```{r}
agr <- d %>% 
  group_by(Category,Task) %>% 
  summarize(MeanAccuracy = mean(Accuracy),
            SD = sd(Accuracy))
print(agr)
```

# Start with Accuracy

```{r}
agr <- d %>% 
  group_by(Task) %>% 
  reframe(MeanAccuracy = mean(Accuracy), 
          CILow = ci.low(Accuracy), 
          CIHigh = ci.high(Accuracy)) %>%
  mutate(YMin = MeanAccuracy - CILow, 
         YMax = MeanAccuracy + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Task,y=MeanAccuracy, fill = Task)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9))

  # theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  # guides(fill = "none")

```

```{r}
agr <- d %>% 
  group_by(Task,Category) %>% 
  reframe(MeanAccuracy = mean(Accuracy), 
          CILow = ci.low(Accuracy), 
          CIHigh = ci.high(Accuracy)) %>%
  mutate(YMin = MeanAccuracy - CILow, 
         YMax = MeanAccuracy + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Task,y=MeanAccuracy, fill = Category)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9))
# ggsave("../graphs/conc-abs_categoryXtask.pdf",width = 5, height = 3)

```



```{r}
agr <- d %>% 
  group_by(Word,Category,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Category)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +
  facet_wrap(~Task)
  # guides(legend = "none")
  # theme(legend.position = "none")  # Remove the legend

# ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Task)) +
#   geom_point() +
#   geom_smooth(aes(color = Task), method = "lm", se = FALSE, size = 1.2) +  # Darker line
#   geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +  
#   scale_color_manual(values = c("Adjs" = "red", 
#                                   "Nouns" = "green", 
#                                   "Verbs" = "blue")) +  # Adjust colors
#   theme(legend.position = "none")  # Remove the legend


# ggsave("../graphs/exp1b_accXrt.pdf",width = 5, height = 3)

```


# Look at the most accurate for each category on Concrete Task

```{r}
# Compute highest accuracy for Concrete, keeping top 10 words per Category
concrete_accuracy <- d %>% 
  group_by(Category, Word, Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime), .groups = "drop") %>% 
  filter(Task == "Concrete") %>%
  select(Category, Word, MeanAccuracy) %>%
  rename(ConcreteAccuracy = MeanAccuracy) %>%
  group_by(Category) %>% 
  slice_max(order_by = ConcreteAccuracy, n = 10)  # Get top 10 per category

agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task,Category) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))

print(agr)

ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5) +
  facet_wrap(~Category) +
  guides(legend = "none") +
  theme(legend.position = "none")  # Remove the legend
# ggsave("../graphs/ConcAbs_accXrt.pdf",width = 5, height = 3)

```

```{r}
agr <- d %>% 
  group_by(Word,Category,Task) %>%
  filter(Word %in% concrete_accuracy$Word) %>% 
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Category)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +
  facet_wrap(~Task)
# ggsave("../graphs/ConcAbs_catXaccXrt.pdf",width = 5, height = 2)
```


```{r}
agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Task)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Separate lines for each Task
  geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +  # Task color inherited from ggplot()
  theme(legend.position = "none")  # Remove the legend

# ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE, color = "black") +
#   geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5) +
#   guides(legend = "none") +
#   theme(legend.position = "none")  # Remove the legend


library(ggrepel)  # Load the ggrepel package

ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Task)) +
  # geom_point() +
  geom_point(size = 2, alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE) +  # Separate lines for each Task
  geom_text_repel(aes(label = Word)) +  # Automatically repel overlapping text labels
  scale_x_continuous(expand = expansion(mult = 0.1)) +  # Adds padding to x-axis
  scale_y_continuous(expand = expansion(mult = 0.1)) +  # Adds padding to y-axis
  theme(legend.position = "none")  # Remove the legend



ggsave("../graphs/ConcAbs_accXrt_2.pdf",width = 6, height = 3)

```


```{r, eval=FALSE, echo=FALSE}
ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Task)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Separate lines for each Task
  geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +  # Task color inherited from ggplot()
  expand_limits(y = max(agr$MeanAccuracy) + 0.05, x = max(agr$MeanReactionTime) + 0.05) +  # Expand limits
  theme(legend.position = "none")  # Remove the legend

ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy, color = Task)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_text(aes(label = Word), vjust = -0.5, hjust = 1.5) +
  scale_x_continuous(expand = expansion(mult = 0.1)) +  # Adds 10% padding to x-axis
  scale_y_continuous(expand = expansion(mult = 0.1)) +  # Adds 10% padding to y-axis
  theme(legend.position = "none")
```


```{r}
agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>% 
  reframe(MeanAccuracy = mean(Accuracy), 
          CILow = ci.low(Accuracy), 
          CIHigh = ci.high(Accuracy)) %>%
  mutate(YMin = MeanAccuracy - CILow, 
         YMax = MeanAccuracy + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanAccuracy, fill = Task)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
agr <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task,Category) %>% 
  reframe(MeanReactionTime = mean(ReactionTime), 
          CILow = ci.low(ReactionTime), 
          CIHigh = ci.high(ReactionTime)) %>%
  mutate(YMin = MeanReactionTime - CILow, 
         YMax = MeanReactionTime + CIHigh)
# View(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanReactionTime, fill = Category)) +
  geom_bar(position=dodge,stat="identity") + 
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  facet_wrap(~Task) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## In these most accurate words, is there still our effect?

```{r}
names(d)
dcen <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  mutate(Word = as.factor(Word),
         ID.true = as.factor(ID.true),
         Task = as.factor(Task),
         Category = as.factor(Category),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cTask = as.numeric(Task)-mean(as.numeric(Task)))

m <- lmer(LogReactionTime ~ cAccuracy*cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m)

m.s <- lmer(LogReactionTime ~ cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)

anova(m,m.s, test="chisq")

m.c <- lmer(LogReactionTime ~ cAccuracy*cTask*Category + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m.c)

```

# Look within categorieslexical  

### Adjectives
```{r}
d$Category = as.factor(d$Category)
str(d$Category)
dcen <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  filter(Category == "Adjs") %>% 
  mutate(Word = as.factor(Word),
         ID.true = as.factor(ID.true),
         Task = as.factor(Task),
         Category = as.factor(Category),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cTask = as.numeric(Task)-mean(as.numeric(Task)))

m <- lmer(LogReactionTime ~ cAccuracy*cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m)

m.s <- lmer(LogReactionTime ~ cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)

anova(m,m.s, test="chisq")

```


### Verbs
```{r}
dcen <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  filter(Category == "Verbs") %>% 
  mutate(Word = as.factor(Word),
         ID.true = as.factor(ID.true),
         Task = as.factor(Task),
         Category = as.factor(Category),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cTask = as.numeric(Task)-mean(as.numeric(Task)))

m <- lmer(LogReactionTime ~ cAccuracy*cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m)

m.s <- lmer(LogReactionTime ~ cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)

anova(m,m.s, test="chisq")

```


#### Nouns
```{r}
dcen <- d %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  filter(Category == "Nouns") %>% 
  mutate(Word = as.factor(Word),
         ID.true = as.factor(ID.true),
         Task = as.factor(Task),
         Category = as.factor(Category),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)),
         cTask = as.numeric(Task)-mean(as.numeric(Task)))

m <- lmer(LogReactionTime ~ cAccuracy*cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)
summary(m)

m.s <- lmer(LogReactionTime ~ cTask + (1+cTask|Word) + (1+cTask|ID.true), data = dcen)

anova(m,m.s, test="chisq")

```


## By Participant

```{r}
agr <- d %>%
    group_by(ID.true,Task) %>%
    reframe(MeanAccuracy = mean(Accuracy), 
            CILow = ci.low(Accuracy), 
            CIHigh = ci.high(Accuracy)) %>%
    mutate(YMin = MeanAccuracy - CILow, 
           YMax = MeanAccuracy + CIHigh)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=reorder(ID.true,MeanAccuracy),y=MeanAccuracy,fill=Task)) +
  geom_bar(position=dodge,stat="identity") +
  facet_wrap(~Task) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")
```





# Accuracy by Task
```{r}

agr <- d %>% 
  group_by(Word,Task,Category) %>% 
  reframe(MeanAccuracy = mean(Accuracy), 
          CILow = ci.low(Accuracy), 
          CIHigh = ci.high(Accuracy)) %>%
  mutate(YMin = MeanAccuracy - CILow, 
         YMax = MeanAccuracy + CIHigh)

ggplot(agr, aes(x=Task, y=MeanAccuracy,fill=Category)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2))
  # guides(fill = "none")

```


# By Participant

```{r}
agr <- d %>%
    group_by(ID.true,Task,ConcValCombo) %>%
    summarize(MeanReactionTime = mean(ReactionTime), 
              CILow = ci.low(ReactionTime), 
              CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=reorder(ID.true,MeanReactionTime),y=MeanReactionTime,fill=ConcValCombo)) +
  geom_bar(position=dodge,stat="identity") +
  facet_wrap(~Task) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")
```










# Looking at Responses Generally

## Proportion Concrete
```{r}
agr <- d %>% 
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1) %>% 
  group_by(ConcValCombo,Category) %>%
  summarize(PropConcrete = mean(Response.n),
          CILow = ci.low(Response.n), 
          CIHigh = ci.high(Response.n)) %>%
  mutate(YMin = PropConcrete - CILow, 
          YMax = PropConcrete + CIHigh)


dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Category,y=PropConcrete,fill=ConcValCombo)) +
  geom_bar(position=dodge,stat="identity") +
  # facet_wrap(~Version) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9))
  # theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
agr <- d %>% 
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1) %>% 
  group_by(Word,ConcValCombo) %>%
  summarize(PropConcrete = mean(Response.n),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = PropConcrete)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_text(aes(label = Word, color = ConcValCombo), vjust = -0.5, hjust = 1.5) 
  # geom_text_repel(aes(label = Word, color = ConcValCombo), 
                  # vjust = -0.5, hjust = 1.5) +
  # scale_fill_manual(values=cbPalette) +
  # scale_color_manual(values=cbPalette)

```


```{r}
agr <- d %>% 
  filter(Task == "Valence") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("negative", "positive"))) - 1) %>% 
  group_by(Word,ConcValCombo) %>%
  summarize(PropPositive = mean(Response.n),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = PropPositive)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_text(aes(label = Word, color = ConcValCombo), vjust = -0.5, hjust = 1.5) 
  # geom_text_repel(aes(label = Word, color = ConcValCombo), 
                  # vjust = -0.5, hjust = 1.5) +
  # scale_fill_manual(values=cbPalette) +
  # scale_color_manual(values=cbPalette)

```

```{r}
agr <- d %>% 
  # filter(Task == "Concrete") %>% 
  # mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1) %>% 
  group_by(Word,Task,Category) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))


ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  facet_wrap(~Task) +
  geom_text(aes(label = Word, color = Category), vjust = -0.5, hjust = 1.5) +
  guides(legend = "none")
  #   theme(
  #   legend.position = "top",    # Move legend to the top
  #   legend.title = element_text(size = 10),  # Adjust legend title size
  #   legend.text = element_text(size = 9)     # Adjust legend text size
  # )
  

  # geom_text_repel(aes(label = Word, color = ConcValCombo), 
                  # vjust = -0.5, hjust = 1.5) +
  # scale_fill_manual(values=cbPalette) +
  # scale_color_manual(values=cbPalette)

# ggsave("../graphs/exp3_accXrt.pdf",width = 5, height = 3)

```



# Reaction Time analyses


## Data Cleaning

```{r}
# First remove inaccurate participants
length(unique(d$ID.true))
inacc.parts <- d %>% 
  group_by(ID.true,Task,Category) %>% 
  summarise(MeanAccuracy = mean(Accuracy)) %>% 
  filter(MeanAccuracy < .75)
# How many participants have Accuracy < .75?
length(unique(inacc.parts$ID.true))
# Remove them
d.inaccurate.removed <- d %>% 
  anti_join(inacc.parts, by = "ID.true")
# Sanity check
length(unique(d.inaccurate.removed$ID.true))


# Second, remove all inaccurate trials
orig <- nrow(d.inaccurate.removed)
d.inaccurate.removed <- d.inaccurate.removed %>% 
  filter(Accuracy == 1)
nrow(d.inaccurate.removed)/orig*100


# Third, Remove subjects with ReactionTime higher than 3x IQR
summary(d.inaccurate.removed$LogReactionTime)
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 6.924   7.328   7.436   7.479   7.579  10.008 
range(d.inaccurate.removed$LogReactionTime)

hist(d.inaccurate.removed$LogReactionTime, breaks=100, col="lightblue", xlab="LogReactionTime (ms)",
        main="Histogram with Normal Curve")

quantile(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)
IQR(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)*3 # 0.7526289
cutoff.high <- quantile(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)[4] + IQR(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)*3 # 8.419261
cutoff.low <- quantile(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)[2] - IQR(d.inaccurate.removed$LogReactionTime, na.rm = TRUE)*3# 6.5088838.419261


# remove subjects with ReactionTime higher than 3 x IQR
df.outliers.removed <- subset(d.inaccurate.removed, (d.inaccurate.removed$LogReactionTime > cutoff.low) & (d.inaccurate.removed$LogReactionTime < cutoff.high))

hist(df.outliers.removed$LogReactionTime, breaks=100, col="lightblue", xlab="LogReactionTime (ms)",
        main="Histogram with Normal Curve")


```


```{r}
ggplot(df.outliers.removed, aes(x=LogReactionTime, fill=Task)) +
  # facet_wrap(~BlockOrder) +
  geom_density(alpha = .4)

ggplot(df.outliers.removed, aes(x=ReactionTime, fill=Task)) +
  # facet_wrap(~BlockOrder) +
  geom_density(alpha = .4)


```

## Summary Stats
```{r}
agr <- d.inaccurate.removed %>% 
  group_by(Task,Category) %>% 
  summarize(MeanRT = mean(ReactionTime),
            SD = sd(ReactionTime),
            MeanLogRT = mean(LogReactionTime))
print(agr)
```



# LogReactionTime by Task

```{r}

agr <- df.outliers.removed %>%
    group_by(Task,Word) %>%
    summarize(MeanLogReactionTime = mean(LogReactionTime), 
              CILow = ci.low(LogReactionTime), 
              CIHigh = ci.high(LogReactionTime)) %>%
    mutate(YMin = MeanLogReactionTime - CILow, 
           YMax = MeanLogReactionTime + CIHigh)

ggplot(agr, aes(x=MeanLogReactionTime, fill=Task)) +
  geom_density(alpha = .4)

ggplot(agr, aes(x=Task, y=MeanLogReactionTime,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    # geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position="dodge", show.legend = FALSE) +
  # theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(fill = "none")

```

# ReactionTime by Task
```{r}

agr <- df.outliers.removed %>%
    group_by(Task,Word,Category) %>%
    summarize(MeanReactionTime = mean(ReactionTime), 
              CILow = ci.low(ReactionTime), 
              CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

ggplot(agr, aes(x=Category, y=MeanReactionTime,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
  guides(fill = "none")

ggsave("../graphs/exp1_abs.pdf",width = 3, height = 2)
ggsave("../graphs/exp1_pres.pdf",width = 5, height = 4)
```

# Analysis






# Prop Conc/Val 
```{r}
prop <- d %>% 
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1) %>% 
  group_by(Word) %>%
  summarize(PropConcrete = mean(Response.n))


agr <- df.outliers.removed %>% 
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1) %>% 
  group_by(Word,ConcValCombo) %>%
  summarize(PropConcrete = mean(Response.n),
            MeanReactionTime = mean(ReactionTime))

ggplot(agr, aes(x = MeanReactionTime, y = PropConcrete)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  geom_text(aes(label = Word,color=ConcValCombo), vjust = -0.5, hjust = 1.5) 
  # geom_text_repel(aes(label = Word, color = ConcValCombo), 
                  # vjust = -0.5, hjust = 1.5) +
  # scale_fill_manual(values=cbPalette) +
  # scale_color_manual(values=cbPalette)
```


# Does REsponse choice influence RT??

## Valence
Yes, looks like choosing negative is faster than choosing positive d
```{r, include=FALSE, warning=FALSE, echo=FALSE}

center = df.outliers.removed %>%
  filter(Task == "Valence") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("negative", "positive"))) - 1,
  cResponse = as.numeric(Response.n)-mean(as.numeric(Response.n)))

m = lmer(LogReactionTime ~ cResponse + (1|ID.true) + (1|Word), data=center)
summary(m)
```

## Concrete
just barely, choosing abstract has a negative effect on RT
```{r, include=FALSE, warning=FALSE, echo=FALSE}

center = df.outliers.removed %>%
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1,
  cResponse = as.numeric(Response.n)-mean(as.numeric(Response.n)))

m = lmer(LogReactionTime ~ cResponse + (1|ID.true) + (1|Word), data=center)
summary(m)
```



# Category

```{r}
agr <- df.outliers.removed %>%
    group_by(Task,Category) %>%
    reframe(MeanReactionTime = mean(ReactionTime), 
            CILow = ci.low(ReactionTime), 
            CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=reorder(Category,MeanReactionTime),y=MeanReactionTime,fill=Task)) +
  geom_bar(position=dodge,stat="identity") +
  # facet_wrap(~Task) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")


```

# ReactionTime by Task
```{r}

agr <- df.outliers.removed %>%
    group_by(Word,Task,Category) %>%
    reframe(MeanReactionTime = mean(ReactionTime), 
            CILow = ci.low(ReactionTime), 
            CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

ggplot(agr, aes(x=Category, y=MeanReactionTime,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    guides(fill = "none")

```


# Look at cases where RT Conc <= RT Valence or Conc Acc >= Val Acc

```{r}
test <- df.outliers.removed %>%
  # filter(Task %in% c("Concrete", "Valence")) %>%  # Keep only relevant tasks
  group_by(Word, Task) %>%
  summarise(
    RT = mean(ReactionTime, na.rm = TRUE),  # Take the mean RT if duplicates exist
    .groups = "drop_last" # Drop grouping by Task but keep Word and ID.true
  ) %>%
  pivot_wider(names_from = Task, values_from = RT, names_prefix = "RT_") %>% # Reshape to wide format
  filter(RT_Concrete <= RT_Valence) %>%  # Apply the condition
    pivot_longer(
    cols = starts_with("RT_"), # Select the reshaped columns
    names_to = "Task",         # Restore Task column
    names_prefix = "RT_",      # Remove "RT_" prefix to match original Task names
    values_to = "ReactionTime" # Column for the RT values
  ) %>%
  ungroup()

nrow(test)/nrow(df.outliers.removed)

```

```{r,fig.width=10, fig.height=10}
agr <- test %>% 
    group_by(Word, Task) %>%
    summarize(MeanReactionTime = mean(ReactionTime), 
            CILow = ci.low(ReactionTime), 
            CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Task,y=MeanReactionTime,fill=Task)) +
  geom_bar(position=dodge,stat="identity") +
  facet_wrap(~Word) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")

```

```{r}
ggplot(agr,aes(x=Word, y=MeanReactionTime, alpha=Task, fill=Task)) +
  geom_bar(position="dodge",stat="identity") +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  # facet_wrap(~Task, ncol=10) +
  xlab("ConcValCombo") +
  ylab("MeanAccuracy") +
  guides(fill=FALSE) +
  # guides(alpha=guide_legend(title="Task")) +
  theme(legend.key.size = unit(0.3, "cm"),
        legend.position = "top", # c(.5,1)
        legend.direction = "horizontal",
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(0,0,-5,-5),legend.spacing.y = unit(0.001, 'cm')) +
    # scale_fill_manual(values=cbPalette) +
    # scale_color_manual(values=cbPalette) +
    scale_alpha_discrete(range = c(.5,1)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r,fig.width=10, fig.height=10}
test_avv <- d %>% 
  filter(Word %in% test$Word) %>% 
  group_by(Word, Task) %>%
    summarize(MeanAccuracy = mean(Accuracy),
            CILow = ci.low(Accuracy), 
            CIHigh = ci.high(Accuracy),
            ) %>%
    mutate(YMin = MeanAccuracy - CILow, 
           YMax = MeanAccuracy + CIHigh)

# View(test_avv)

dodge = position_dodge(.9)
ggplot(data=test_avv, aes(x=Task,y=MeanAccuracy,fill=Task)) +
  geom_bar(position=dodge,stat="identity") +
  facet_wrap(~Word) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")
```


```{r}
test_avv <- d %>% 
  filter(Word %in% test$Word) %>% 
  group_by(Word, Task) %>%
    summarize(MeanAccuracy = mean(Accuracy),
              MeanReactionTime = mean(ReactionTime))


ggplot(test_avv, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  # geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5)
  geom_text_repel(aes(label = Word, color = Task), 
                  vjust = -0.5, hjust = 1.5) +
  scale_fill_manual(values=cbPalette) +
  scale_color_manual(values=cbPalette)
```

# Conc Acc is higher than Val Acc
```{r}
# Compute highest accuracy for Concrete
concrete_accuracy <- d %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime)) %>% 
  filter(Task == "Concrete") %>%
  select(Word, MeanAccuracy) %>%
  rename(ConcreteAccuracy = MeanAccuracy) %>% 
  arrange(desc(ConcreteAccuracy)) %>% 
  head(10)

agr <- df.outliers.removed %>% 
  filter(Word %in% concrete_accuracy$Word) %>% 
  group_by(Word,Task) %>%
  summarize(MeanAccuracy = mean(Accuracy),
            MeanReactionTime = mean(ReactionTime))

print(agr)

ggplot(agr, aes(x = MeanReactionTime, y = MeanAccuracy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  geom_text(aes(label = Word, color = Task), vjust = -0.5, hjust = 1.5)
  # guides(legend = "none")
  # theme(legend.position = "none")  # Remove the legend
# ggsave("../graphs/exp1b_accXrt.pdf",width = 5, height = 3)

```

```{r,fig.width=10, fig.height=10}
agr <- df.outliers.removed %>% 
    filter(Word %in% concrete_accuracy$Word) %>% 
    group_by(Word, Task) %>%
    summarize(MeanReactionTime = mean(ReactionTime), 
            CILow = ci.low(ReactionTime), 
            CIHigh = ci.high(ReactionTime)) %>%
    mutate(YMin = MeanReactionTime - CILow, 
           YMax = MeanReactionTime + CIHigh)

print(agr)

dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanReactionTime,fill=Task)) +
  geom_bar(position=dodge,stat="identity") +
  # facet_wrap(~Word) +
  geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position=position_dodge(0.9)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  # guides(fill = "none")

```


```{r}

agr <- df.outliers.removed %>%
  filter(Word %in% concrete_accuracy$Word)

ggplot(agr, aes(x=Word, y=ReactionTime,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    # Median dot
    stat_summary(fun = median, geom = "point", 
                 shape = 21, size = 1.5, 
                 position = position_dodge(width=0.9)) +  # Centering the median dot
    # geom_jitter(shape=10, position=position_jitter(0.2)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
    # guides(fill = "none")
```



#  Analysis
convert everything to factors
```{r, include=FALSE, warning=FALSE, echo=FALSE}
# str(d)

convert_except <- function(df, exclude_cols) {
  df[] <- lapply(names(df), function(col_name) {
    if (!(col_name %in% exclude_cols)) {
      return(as.factor(df[[col_name]]))  # Convert to factor if not in excluded columns
    } else {
      return(df[[col_name]])  # Leave the excluded columns unchanged
    }
  })
  return(df)
}
# Specify columns to exclude from conversion
exclude_columns <- c('ReactionTime', 'LogReactionTime','SecondWordLogRT')

# Convert all columns to factors except for 'a' and 'd'
df_factors <- convert_except(df.outliers.removed, exclude_columns)

# Check the structure of the modified data frame
# str(df_factors)

```


```{r, include=FALSE, warning=FALSE, echo=FALSE}
# contrasts(df_factors$SwitchCombo)
contrasts(df_factors$Task)
contrasts(df_factors$Category)

# reset category contrasts so noun is vase
contrasts(df_factors$Category) <- contr.treatment(3, base = 2)

contrasts(df_factors$Category)

center = df_factors %>%
  mutate(
         cTask = as.numeric(Task)-mean(as.numeric(Task))         )
  
  # droplevels()
```

# Is there a difference between Semantic and Valence Tasks?
Yes

```{r}

m = lmer(LogReactionTime ~ cTask + (1+cTask|ID.true) + (1+cTask|Word), data=center)
summary(m)
```

```{r}
table(center$Category)
m = lmer(LogReactionTime ~ Category + (1+Category|ID.true) + (1|Word), data=center)
summary(m)
```

```{r}

m = lmer(LogReactionTime ~ cTask*Category + (1+cTask|ID.true) + (1+cTask|Word), data=center)
summary(m)
```

# In the Concreteness task, is there a difference between concreteness and abstractness on ReactionTime?
- Nope
```{r}
str(df_factors)
conc <- df_factors %>% 
  filter(Task == "Concrete") %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("abstract", "concrete"))) - 1,
         Concrete = ifelse(grepl("abstract", ConcValCombo), "abstract", 
                    ifelse(grepl("concrete", ConcValCombo), "concrete", NA)),
        cConcValCombo = as.numeric(ConcValCombo) - mean(as.numeric(ConcValCombo)),
        cConcrete = as.numeric(as.factor(Concrete)) - mean(as.numeric(as.factor(Concrete))),
        # cSyntactic = as.numeric(factor(Syntactic)) - mean(as.numeric(factor(Syntactic)))
  )
```

```{r}
m = lmer(LogReactionTime ~ cConcValCombo + (1+cConcValCombo|ID.true) + (1+cConcValCombo|Word), data=conc)
summary(m)

```

No effect of word concreteness
```{r}
m = lmer(LogReactionTime ~ cConcrete + (1+cConcrete|ID.true) + (1|Word), data=conc)
summary(m)

```

Small effect of response choice
```{r}
m = lmer(LogReactionTime ~ Response.n + (1|ID.true) + (1|Word), data=conc)
summary(m)

```


# In the Valence task , is there a difference between positive and negative on ReactionTime?
- Nope.
```{r}
val <- df.outliers.removed %>% 
  filter(Task == "Valence") %>%
  filter(!is.na(ConcValCombo)) %>% 
  mutate(Response.n = as.numeric(factor(Response, levels = c("negative", "positive"))) - 1,
         Valence = case_when(
                        grepl("negative", ConcValCombo) ~ "negative",
                        grepl("positive", ConcValCombo) ~ "positive",
                        TRUE ~ NA_character_
                    ),
         # Valence = ifelse(grepl("negative", ConcValCombo), "negative", 
         #            ifelse(grepl("positive", ConcValCombo), "positive", NA)),
        cConcValCombo = as.numeric(as.factor(ConcValCombo)) - mean(as.numeric(as.factor(ConcValCombo))),
        cValence = as.numeric(as.factor(Valence)) - mean(as.numeric(as.factor(Valence)))
  )


sum(is.na(val$ConcValCombo))  # Count missing values
sum(is.na(val$LogReactionTime)) # Check for missing LogReactionTime
var(val$cConcValCombo)
unique(val$ConcValCombo)
# View(val)
# valna <- val %>% 
#   filter(is.na(val$ConcValCombo))

```


```{r}
m = lmer(LogReactionTime ~ cConcValCombo + (1+cConcValCombo|ID.true) + (1+cConcValCombo|Word), data=val)
summary(m)

```

Effect of Word Valence
```{r}
m = lmer(LogReactionTime ~ cValence + (1+cValence|ID.true) + (1|Word), data=val)
summary(m)
```

Effect of response choice
```{r}
m = lmer(LogReactionTime ~ Response.n + (1|ID.true) + (1|Word), data=val)
summary(m)

```

