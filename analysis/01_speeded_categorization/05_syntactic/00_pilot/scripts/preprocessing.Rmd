---
title: 'Pilot Syntactic: preprocessing'
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../helpers.R")
```


```{r}
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}

# Read in the results
vc.a <- read.pcibex("../data/noun-verb_syn-val_SV_A.csv")
vc.a["BlockOrder"] <- "SV"
# vc.a["Group"] <- "A"
length(unique(vc.a$MD5.hash.of.participant.s.IP.address))

vc.b <- read.pcibex("../data/noun-verb_syn-val_SV_B.csv")
vc.b["BlockOrder"] <- "SV"
# vc.b["Group"] <- "B"
length(unique(vc.b$MD5.hash.of.participant.s.IP.address))

cv.a <- read.pcibex("../data/noun-verb_syn-val_VS_A.csv")
cv.a["BlockOrder"] <- "VS"
# cv.a["Group"] <- "A"
length(unique(cv.a$MD5.hash.of.participant.s.IP.address))

cv.b <- read.pcibex("../data/noun-verb_syn-val_VS_B.csv")
cv.b["BlockOrder"] <- "VS"
# cv.b["Group"] <- "B"
length(unique(cv.b$MD5.hash.of.participant.s.IP.address))

facts <- read.csv("../data/nouns-verbs.csv")
facts$ConcValCombo <- gsub("postiive", "positive", facts$ConcValCombo)


d <- rbind(vc.a,cv.a, vc.b, cv.b)
names(d)
length(unique(d$MD5.hash.of.participant.s.IP.address))
```

```{r}
table(d$Group)
```




# Take a look at comments and Problems
```{r}
unique(d$PennElementType)
comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Comments"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Problems"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "NativeLang"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "OtherLangs"))

unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Gender"))
unique(comments$Value)
```

# Add necessary columns

```{r}
names(d)
# get the IDs in the right way
d.IDs <- d %>% 
  select(MD5.hash.of.participant.s.IP.address,ID,Value,Parameter,PennElementName) %>% 
  mutate(ID.true = if_else(PennElementName == "ID" & Parameter == "Final", Value, NA_character_)) %>%  # Value[(PennElementName=="ID") & (Parameter == "Final")])
   select(MD5.hash.of.participant.s.IP.address,ID.true) %>%
   distinct() %>% 
  filter(!is.na(ID.true))
# nrow(d)

d <- d %>%  merge(., d.IDs, by = c("MD5.hash.of.participant.s.IP.address"))

# Separate out the training items
d.train <- d %>% 
  filter(Label %in% c("calibrator_val_feedback","calibrator_syn_feedback","calibrator_val_no_feedback","calibrator_syn_no_feedback"))

d <- d %>%
inner_join(facts, by = "Word")

# Add a Response column# Add a Response column
d$Response <- ""
d$Response <- ifelse(d$Parameter == "Selection", d$Value, d$Response)

# Create the Accuracy column checking if Response is a substring of ConcValCombo
d$Response <- as.character(d$Response)
d$ConcValCombo <- as.character(d$ConcValCombo)
d$Category <- as.character(d$Category)

# Add Task column
d$Task <- ifelse(d$Label == "test_val", "Valence", 
                 ifelse(d$Label == "test_syn", "Syntactic", "Na"))

# Creat Accuracy based on substring matchs
d$Accuracy <- mapply(function(response, conc_val_combo, category, task) {
  if (task == "Valence" && grepl(response, conc_val_combo)) {
    return(1)
  } else if (task == "Syntactic" && grepl(response, category, ignore.case = TRUE)) {
    return(1)
  } else {
    return(0)
  }
}, d$Response, d$ConcValCombo, d$Category, d$Task)


table(d$Task,d$Label)
table(d$Task,d$Value)

d <- d %>% 
    filter(Label %in% c("test_syn","test_val")) %>% 
    filter(Parameter == "Selection") %>%
    select(ID.true,Word,Label,ConcValCombo,Category,Task,BlockOrder,Group,Response,Accuracy,EventTime,Value,ReactionTime,Key_value_F,Key_value_J,Comments) %>% 
  distinct()

# View(d)
d$ReactionTime <- as.numeric(d$ReactionTime)
d$LogReactionTime <- log(d$ReactionTime)

# Add triual number
d <- d %>% 
    group_by(ID.true) %>%           # Group by ID.true
    mutate(TrialNumber = row_number()) %>%   # Create TrialNumber as the row number within each group
    ungroup()  # Ungroup the data to remove the group structure


# Write to .csv
write.csv(d,"../data/processed.csv")

```

# training items to csv

```{r}

# Add Task column
d.train$Task <- ifelse(d.train$Label %in% c("calibrator_val_feedback","calibrator_val_no_feedback"), "Valence", 
                 ifelse(d.train$Label %in% c("calibrator_syn_feedback","calibrator_syn_no_feedback"), "Syntactic", "Na"))
length(unique(d.train$ID.true))

length(unique(d.train$ID.true)) # 40 left

d.train <- d.train %>% 
    filter(Parameter == "Selection") %>%
    select(ID.true,Word,Label,Task,BlockOrder,EventTime,Value,ReactionTime, Key_value_F,Key_value_J,Comments,Group) %>% 
  distinct()

nrow(d.train)


names(d.train)
d.train$ReactionTime <- as.numeric(d.train$ReactionTime)
d.train$LogReactionTime <- log(d.train$ReactionTime)

# Add triual number
d.train <- d.train %>% 
    group_by(ID.true) %>%           # Group by ID.true
    mutate(TrialNumber = row_number()) %>%   # Create TrialNumber as the row number within each group
    ungroup()  # Ungroup the data to remove the group structure

write.csv(d.train,"../data/processed_training.csv")

table(d.train$Task)

```



```{r}
table(d$BlockOrder,d$Group)
table(d.train$BlockOrder,d.train$Group)

table(d$Task,d$Group)
table(d.train$Task,d.train$Group)

```



```{r, eval=FALSE,echo=FALSE}
ggplot(d, aes(EventTime, fill=Task)) +
  geom_density(alpha = .5)

ggplot(d, aes(ReactionTime,fill=Task)) +
  geom_density(alpha = .5)

ggplot(d, aes(LogReactionTime, fill=Task)) +
  facet_wrap(~BlockOrder)+
  geom_density(alpha = .5)
```

