---
title: "Pilot 1: Removing Outliers Analsis"
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../../helpers.R")
d <- read.csv("../data/processed.csv")
d$LogReactionTime <- log(d$ReactionTime)
```

```{r}
summary(d$LogReactionTime)
```

```{r}

ggplot(d, aes(x=LogReactionTime)) +
  geom_histogram(binwidth = .1,fill = "lightblue", color = "black") +
  facet_wrap(~Task)

ggplot(d, aes(x=LogReactionTime, fill=Task)) +
  geom_density(alpha = .4)

```

# First Remove participants who aren't accurate, grouping by Task

```{r}
length(unique(d$ID.true))
inacc.parts <- d %>% 
  group_by(Task,ID.true) %>% 
  summarise(MeanAccuracy = mean(Accuracy)) %>% 
  filter(MeanAccuracy < .75)

# How many participants have accuracy < .75?
length(unique(inacc.parts$ID.true))

d.inaccurate.removed <- d %>% 
  anti_join(inacc.parts, by = "ID.true")

# Sanity check
length(unique(d.inaccurate.removed$ID.true))


ggplot(d.inaccurate.removed, aes(x=LogReactionTime, fill=Task)) +
  geom_density(alpha = .4)
```


```{r}
# Remove subjects with ReactionTime higher than 3x IQR
summary(d.inaccurate.removed$LogReactionTime)
  #  Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  # 6.924   7.328   7.436   7.479   7.579  10.008 
range(d.inaccurate.removed$LogReactionTime)

hist(d.inaccurate.removed$LogReactionTime, breaks=100, col="lightblue", xlab="LogReactionTime (ms)",
        main="Histogram with Normal Curve")

quantile(d.inaccurate.removed$LogReactionTime)
IQR(d.inaccurate.removed$LogReactionTime)*3 # 0.7526289
cutoff.high <- quantile(d.inaccurate.removed$LogReactionTime)[4] + IQR(d.inaccurate.removed$LogReactionTime)*3 # 8.419261
cutoff.low <- quantile(d.inaccurate.removed$LogReactionTime)[2] - IQR(d.inaccurate.removed$LogReactionTime)*3# 6.5088838.419261


# remove subjects with ReactionTime higher than 3 x IQR
df.outliers.removed <- subset(d.inaccurate.removed, (d.inaccurate.removed$LogReactionTime > cutoff.low) & (d.inaccurate.removed$LogReactionTime < cutoff.high))

# hist(df.outliers.removed$LogReactionTime, col="lightblue", xlab="LogReactionTime (ms)",
#         main="Histogram with Normal Curve")

ggplot(df.outliers.removed, aes(x=LogReactionTime, fill=Task)) +
  geom_density(alpha = .4)

```

```{r}
df.outliers.removed$Task <- as.factor(df.outliers.removed$Task)
df.outliers.removed$Word <- as.factor(df.outliers.removed$Word)
df.outliers.removed$ID.true <- as.factor(df.outliers.removed$ID.true)
df.outliers.removed$ConcValCombo <- as.factor(df.outliers.removed$ConcValCombo)

center = df.outliers.removed %>%
  mutate(cTask = as.numeric(Task)-mean(as.numeric(Task)),
         cAccuracy = as.numeric(Accuracy)-mean(as.numeric(Accuracy)))
```

# Is there a difference between Semantic and Valence Tasks?
Hmm....no

```{r}

m = lmer(LogReactionTime ~ cTask + (1|ID.true) + (1+cTask|Word), data=center)
# saveRDS(m.ms.ma.full, "../models/model-task-para.rds")

# m <- readRDS("../models/m.rds")
summary(m)
```

# Is there an Interaction between Task and WordType (ConcValCombo)?
Still no.
```{r}

m = lmer(LogReactionTime ~ cTask*ConcValCombo + (1+ConcValCombo|ID.true) + (1+cTask+ConcValCombo|Word), data=center)
# saveRDS(m.ms.ma.full, "../models/model-task-para.rds")

# m <- readRDS("../models/m.rds")
summary(m)

```

