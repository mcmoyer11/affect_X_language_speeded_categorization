---
title: 'Pilot 2 (extreme words): preprocessing'
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../../helpers.R")
```


```{r}
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
  n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
  if (auto.colnames){
    cols <- c()
    con <- file(filepath, "r")
    while ( TRUE ) {
      line <- readLines(con, n = 1, warn=FALSE)
      if ( length(line) == 0) {
        break
      }
      m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
      if (length(m) == 3) {
        index <- as.numeric(m[2])
        value <- m[3]
        if (is.function(fun.col)){
         cols <- fun.col(value,cols)
        }
        cols[index] <- value
        if (index == n.cols){
          break
        }
      }
    }
    close(con)
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
  }
  else{
    return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
  }
}

# Read in the results
cv <- read.pcibex("../data/results_cv.csv")
vc <- read.pcibex("../data/results_vc.csv")

cv["BlockOrder"] <- "CV"
vc["BlockOrder"] <- "VC"
d <- rbind(cv,vc)
unique(d$Label)
```



# Take a look at comments and Problems
```{r}
unique(d$PennElementType)
comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Comments"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Problems"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "NativeLang"))
unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "OtherLangs"))

unique(comments$Value)

comments <- d %>% filter((PennElementType == "TextInput") & (PennElementName == "Gender"))
unique(comments$Value)
```

# Add necessary columns

```{r}
# get the IDs in the right way
d.IDs <- d %>% select(MD5.hash.of.participant.s.IP.address,ID,Value,Parameter,PennElementName) %>% 
  mutate(ID.true = if_else(PennElementName == "ID" & Parameter == "Final", Value, NA_character_)) %>%  # Value[(PennElementName=="ID") & (Parameter == "Final")])
   select(MD5.hash.of.participant.s.IP.address,ID.true) %>%
   distinct() %>% 
  filter(!is.na(ID.true))

d <- d %>%  merge(., d.IDs, by = c("MD5.hash.of.participant.s.IP.address"))

# Separate out the training items
d.train <- d %>% 
  filter(Label %in% c("calibrator_val","calibrator_conc"))

# get the relevant conc and val info for each word
# This code will automativally remove the training items so have to separate them
# before running this code
d.labels.test <- read.csv("../data/weighted_extreme_facts.csv")[,c("Word","ConcValCombo_moderate")] %>% 
  rename(ConcValCombo = ConcValCombo_moderate) %>% 
  distinct(Word, .keep_all=TRUE)

d <- inner_join(d, d.labels.test, by = "Word")

# Add a Response column# Add a Response column
# d$Response <- d$Value[d$Parameter=="Selection"]
d$Response <- ""
d$Response <- ifelse(d$Parameter == "Selection", d$Value, d$Response)

# Add RT measure Column >>> How is this different from the REactionTime column from the code?
results <- d %>%
  filter( Parameter == "Selection" | Value == "Start") %>%
  group_by(ID.true,Word) %>%
  summarise( RT = mean(EventTime[Parameter=="Selection"] - EventTime[Value=="Start"]) , N = length(Value)/2 ) %>% 
  select(-c("N"))

# Combine together
d <- inner_join(d,results, by = c("ID.true","Word") )

# Create the Accuracy column checking if Response is a substring of ConcValCombo
d$Response <- as.character(d$Response)
d$ConcValCombo <- as.character(d$ConcValCombo)

d$Accuracy <- mapply(function(response, pattern) {
  ifelse(grepl(response, pattern), 1, 0)
}, d$Response, d$ConcValCombo)


# Add Task column
d$Task <- ifelse(d$Label == "test_val", "Valence", 
                 ifelse(d$Label == "test_conc", "Concrete", "Na"))

table(d$Task,d$Label)

table(d$BlockOrder,d$Task)
```

# Remove the participants from the cv block with the bad code
```{r}

# Find rows of ID.true where Label has "test_val" but not "test_conc"
filtered_ids <- d %>%
  group_by(ID.true) %>%               # Group by ID.true
  filter(any(Label == "test_val") &    # Keep those that have "test_val"
         !any(Label == "test_conc")) %>%  # But do not have "test_conc"
  ungroup()  # Optional: ungroup the data after the operation

table(filtered_ids$Task,filtered_ids$Label)
# View the result
to_remove <- unique(filtered_ids[,c("ID.true")])

# Remove rows from `df` where ID.true matches any ID in filtered_ids
d <- d %>%
  anti_join(filtered_ids, by = "ID.true")
nrow(d)
table(d$BlockOrder,d$Task)
table(d$Task,d$Label)
table(d$BlockOrder,d$Task,d$Label)
```


```{r}
d <- d %>% 
    filter(Parameter == "Selection") %>%
    select(ID.true,Word,Label,ConcValCombo,Task,BlockOrder,Group,Response,Accuracy,EventTime,Value,RT,ReactionTime,Key_value_F,Key_value_J,Comments) %>% 
  distinct()

# View(d)
d$ReactionTime <- as.numeric(d$ReactionTime)
d$LogReactionTime <- log(d$ReactionTime)
d$RT <- as.numeric(d$RT)
d$LogRT <- log(d$RT)


# Add triual number
d <- d %>% 
    group_by(ID.true) %>%           # Group by ID.true
    mutate(TrialNumber = row_number()) %>%   # Create TrialNumber as the row number within each group
    ungroup()  # Ungroup the data to remove the group structure

```

# Write to .csv
```{r}
# write.csv(d,"../data/processed.csv")

```

# training items to csv

```{r}

# Add Task column
d.train$Task <- ifelse(d.train$Label == "calibrator_val", "Valence", 
                 ifelse(d.train$Label == "calibrator_conc", "Concrete", "Na"))
length(unique(d.train$ID.true))
# Remove rows from `df` where ID.true matches any ID in filtered_ids
d.train <- d.train %>%
  anti_join(filtered_ids, by = "ID.true")

length(unique(d.train$ID.true)) # 40 left

d.train <- d.train %>% 
    filter(Parameter == "Selection") %>%
    select(ID.true,Word,Label,Task,BlockOrder,EventTime,Value,ReactionTime, Key_value_F,Key_value_J,Comments,Group) %>% 
  distinct()

nrow(d.train)


names(d.train)
d.train$ReactionTime <- as.numeric(d.train$ReactionTime)
d.train$LogReactionTime <- log(d.train$ReactionTime)

# Add triual number
d.train <- d.train %>% 
    group_by(ID.true) %>%           # Group by ID.true
    mutate(TrialNumber = row_number()) %>%   # Create TrialNumber as the row number within each group
    ungroup()  # Ungroup the data to remove the group structure

# write.csv(d.train,"../data/processed_training.csv")

```




```{r, eval=FALSE,echo=FALSE}
ggplot(results, aes(RT)) +
  geom_density(alpha = .5)

ggplot(d, aes(EventTime)) +
  geom_density(alpha = .5)

ggplot(d, aes(ReactionTime)) +
  geom_density(alpha = .5)
```




# text_conc code : is the label for the choices correct?
```{r}
test.conc <- d %>% 
  filter(Label=="test_conc")

View(test.conc)

table(test.conc$Key_value_F,test.conc$Group,test.conc$BlockOrder)

```


```{r}

test <- d %>% 
  filter(BlockOrder == "CV") 
nrow(test)
table(test$Group, test$Task)

table(test$ID.true)

table(test$Label,test$Word)

```

```{r}
part <- d %>% 
  filter(ID.true == "66208c9103c058c33d4f9320")

table(part$Label,part$Word)

part.val <- part %>% 
  filter(Label == "test_val") %>% 
  group_by(Word)


View(part.val)

table(part.val$Word)

```

# Compare RT and REaction Time columns
```{r}

View(d)
ggplot(part.val, aes(RT)) +
  geom_density(alpha = .5)

ggplot(part.val, aes(ReactionTime)) +
  geom_density(alpha = .5)

```



# Double check that the accuracy colmns is doing what it should

```{r}
acc.test <- d[,c("ID.true","Word","Task","ConcValCombo","Accuracy","Parameter","Value","Response","Key_value_F","Key_value_J")]
nrow(acc.test) / 5

acc.test <- acc.test[acc.test$Parameter=="Selection",]
nrow(acc.test)

# Do Value and Response Agree?
acc.test$SanityCheck <- ifelse(acc.test$Value == acc.test$Response, "Yes", "No")
table(acc.test$SanityCheck)

# Do the values of Value contain any substring of ConcValCombo
# Create new column based on whether 'Value' contains a substring of 'ConcValCombo'
acc.test$SanityCheckCVCV <- mapply(function(value, combo) grepl(combo, value), acc.test$Value, acc.test$ConcValCombo)
# Convert TRUE/FALSE to Yes/No
acc.test$SanityCheckCVCV <- ifelse(acc.test$SanityCheckCVCV, "Yes", "No")
table(acc.test$SanityCheckCVCV)

# Do the values of Response contain any substrings of ConcValCombo? 
acc.test$SanityCheckCVCR <- mapply(function(value, combo) grepl(combo, value), acc.test$Response, acc.test$ConcValCombo)
# Convert TRUE/FALSE to Yes/No
acc.test$SanityCheckCVCR <- ifelse(acc.test$SanityCheckCVCR, "Yes", "No")
table(acc.test$SanityCheckCVCR)

# View(acc.test)
table(acc.test$Accuracy)

agr <- acc.test %>% 
  group_by(Task) %>% 
  mutate(MeanAccuracy = mean(Accuracy))
  
dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Task,y=MeanAccuracy)) +
  geom_bar(position=dodge,stat="identity")


agr <- acc.test %>% 
  group_by(Task, Word) %>% 
  mutate(MeanAccuracy = mean(Accuracy))
  
dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Word,y=MeanAccuracy, fill=Task)) +
  geom_bar(position=dodge,stat="identity")

```




# Double check things are ok with Task

```{r}

table(d$Task,d$Label)
unique(cv$Label)

table(d$Task,d$BlockOrder)
```





```{r}
ggplot(d, aes(x=LogRT, fill=Task)) +
  facet_wrap(~BlockOrder) +
  geom_density(alpha = .4)
```


# Compare the RT and ReactionTime columns
```{r}


agr.rt1 = d %>%
    group_by(Task,Word) %>%
    summarize(MeanLogReactionTime = mean(LogReactionTime), 
              CILow = ci.low(LogReactionTime), 
              CIHigh = ci.high(LogReactionTime)) %>%
    mutate(YMin = MeanLogReactionTime - CILow, 
           YMax = MeanLogReactionTime + CIHigh)

agr.rt2 = d %>%
    group_by(Task,Word) %>%
    summarize(MeanLogRT = mean(LogRT), 
              CILow = ci.low(LogRT), 
              CIHigh = ci.high(LogRT)) %>%
    mutate(YMin = MeanLogRT - CILow, 
           YMax = MeanLogRT + CIHigh)

```

```{r}


ggplot(agr.rt1, aes(x=MeanLogReactionTime, fill=Task)) +
  geom_density(alpha = .4)

ggplot(agr.rt2, aes(x=MeanLogRT, fill=Task)) +
  geom_density(alpha = .4)
```


```{r}

ggplot(agr.rt1, aes(x=Task, y=MeanLogReactionTime,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    # geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position="dodge", show.legend = FALSE) +
  # theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(fill = "none")


ggplot(agr.rt2, aes(x=Task, y=MeanLogRT,fill=Task)) + 
    geom_violin(trim=FALSE,alpha=.4) +
    geom_jitter(shape=16, position=position_jitter(0.2)) +
    # geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25,position="dodge", show.legend = FALSE) +
  # theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  guides(fill = "none")
```






