---
title: "Extreme Weighted: Human Pilot vs. ChatGPT"
author: "morgan moyer"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(lme4)
library(lmerTest)
library(multcomp) # not available for this version of R
library(stringr)
library(textstem)
library(tidyverse)
library(car)
library(irr)
library(MASS)
theme_set(theme_bw())
cbPalette <- c("#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73","#56B4E9", "#D55E00", "#009E73","#999999", "#E69F00","#009E73")
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source("../../../helpers.R")
```


```{r}
# Corpus data from two different heuristics
corpus <- read.csv("../data/weighted_extreme_facts.csv") %>% rename(ConcValCombo = ConcValCombo_moderate)
corpus$DataSource <- "human_corpus"

# Corpus data from two different heuristics
pilot <- read.csv("../data/processed.csv")[,c("ID.true","Word","Task","Response","Accuracy")]
pilot$DataSource <- "human_behavioral"

# ChatGPT choosing the words from the "complete" word list
gpt.val <- read.csv("../data/chatgpt_weighted_val.txt", sep="\t")
gpt.val$DataSource <- "ChatGPT"

gpt.conc <- read.csv("../data/chatgpt_weighted_conc.txt", sep="\t")
gpt.conc$DataSource <- "ChatGPT"


```

# Convert the datasets into proportions

## ChatGPT data
```{r}
# For Concreteness
# Define the function to process a single data frame and create a new data frame with .prop added to its name
process_and_rename_conc_dfs <- function(df_list) {
  # Iterate over the list of data frames
  for (df_name in names(df_list)) {
    # Process the data frame
    processed_df <- df_list[[df_name]] %>%
      mutate(
        Concrete.. = as.numeric(gsub("%", "", Concrete..)),  # Remove % and convert to numeric
        PropConcrete = Concrete.. / 100                     # Convert to proportion
      ) %>%
      select(-c(Concrete.., Abstract..))                     # Drop the unwanted columns

    # Dynamically assign the new data frame with ".prop" added to the name
    new_name <- paste0(df_name, ".prop")
    assign(new_name, processed_df, envir = .GlobalEnv)  # Assign it to the global environment
  }
}

# Example usage
conc_list <- list(
                gpt.conc = gpt.conc
                )  # Replace with actual data frames
process_and_rename_conc_dfs(conc_list)

# Now you should have gpt.pilot.conc.prop, df2.prop, and df3.prop created in the environment.

# For Valence
# Define the function to process a single data frame and create a new data frame with .prop added to its name
process_and_rename_val_dfs <- function(df_list) {
  # Iterate over the list of data frames
  for (df_name in names(df_list)) {
    # Process the data frame
    processed_df <- df_list[[df_name]] %>%
      mutate(
        Positive.. = as.numeric(gsub("%", "", Positive..)),  # Remove % and convert to numeric
        PropPositive = Positive.. / 100                     # Convert to proportion
      ) %>%
      select(-c(Positive.., Negative..))                     # Drop the unwanted columns

    # Dynamically assign the new data frame with ".prop" added to the name
    new_name <- paste0(df_name, ".prop")
    assign(new_name, processed_df, envir = .GlobalEnv)  # Assign it to the global environment
  }
}

val_list <- list(
                gpt.val = gpt.val
                )  # Replace with actual data frames
process_and_rename_val_dfs(val_list)

# Combine them together
gpt <- left_join(gpt.conc.prop,gpt.val.prop, by=c("Word","DataSource"))

```



## Convert Brys/War Likert scale ratings to proportions

```{r}
corpus.prop <- corpus %>% 
  mutate(PropPositive = V.Mean.Sum / 9,
         PropConcrete = Conc.M / 5) %>% 
  select(Word, PropPositive, PropConcrete, DataSource)

```


## Convert Human data into proportions

```{r, echo=FALSE}
conc <- pilot %>% 
  filter(Task == "Concrete") %>% 
  mutate(nResponse = ifelse(Response == "concrete", 1, 0)) %>% 
  select(Word, nResponse, DataSource) %>%
  group_by(Word) %>% 
  # refactor
  summarize( PropConcrete = mean(nResponse),
             DataSource = first(DataSource))


val <- pilot %>% 
    filter(Task == "Valence") %>% 
  # refactor
    mutate(nResponse = ifelse(Response == "positive", 1, 0)) %>% 
    select(Word, nResponse, DataSource) %>%
    group_by(Word) %>% 
    summarize(PropPositive = mean(nResponse),
              DataSource = first(DataSource))  

human <- left_join(val,conc, by=c("Word","DataSource"))
```

## Combined them 

```{r}
# Combine the dfs
total <- bind_rows(human,corpus.prop,gpt) %>% 
  pivot_longer(cols = c(PropPositive, PropConcrete), 
               names_to = "Task", 
               values_to = "Proportion") %>%
  mutate(Task = ifelse(Task == "PropPositive", "Positive", "Concrete"))


```

```{r}

agr <- total %>% 
  group_by(Task,DataSource) %>% 
  mutate(MeanProportion = mean(Proportion))


dodge = position_dodge(.9)
ggplot(data=agr, aes(x=Task,y=MeanProportion,fill=DataSource)) +
  geom_bar(position=dodge,stat="identity") +
  # facet_wrap(~Word,ncol=5) +
  # theme(axis.text.x = element_blank(),  # Remove x-axis labels
        # axis.title.x = element_blank()) # Remove x-axis title
  # theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle("Responses by Task and DataSource")

  # guides(fill = "none")


```

```{r,fig.width=10, fig.height=15,}


dodge = position_dodge(.9)
ggplot(data=total, aes(x=Task,y=Proportion,fill=DataSource)) +
    geom_bar(position=dodge,stat="identity") +
    facet_wrap(~Word,ncol=5) +
    ggtitle("Responses by Task and DataSource perWord")


```


# LogOdds
```{r}

# Apply logit transformation
# First for Valence
total$LogOdds <- logit(total$Proportion)


```

### Plot LogOdds for Valence betwen intersective and non-intersective
```{r}
# Create the log-odds plot
ggplot(total, aes(x = Task, y = LogOdds, color=DataSource)) +
  geom_point() +  # Scatter plot for log-odds
  geom_jitter() +
  # geom_line(group = 1) +  # Add a line connecting the points
  labs(title = "Log-Odds (Logit) of Proportion",
       y = "Log-Odds (Logit)",
       x = "Data Source")
```

```{r}
agr <- total %>% 
  group_by(Task,DataSource) %>% 
  mutate(MeanLogOdds = mean(LogOdds))
  
dodge = position_dodge(.9)
ggplot(agr, aes(x = Task, y = MeanLogOdds, fill=DataSource)) +
  geom_bar(position=dodge,stat="identity") +  # Scatter plot for log-odds
  # geom_line(group = 1) +  # Add a line connecting the points
  labs(title = "Mean Log-Odds (Logit) of Proportion",
       y = "Mean Log-Odds (Logit)",
       x = "Data Source")

```
